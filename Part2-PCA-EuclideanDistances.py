# -*- coding: utf-8 -*-
"""Project Part 2 - Tasks 4-5.ipynb

Automatically generated by Colaboratory.

Original file is located at

"""

import csv
from email import header
from hashlib import new
import matplotlib.pyplot as plt
import calendar
import numpy as np
import random
import statistics
import scipy.stats as stats
from sklearn.decomposition import PCA
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import cosine_similarity
from scipy.spatial.distance import mahalanobis
import scipy as sp

# Task 4 --- PCA


# reading the dataset
df= pd.read_csv('CAvideos.csv', 
low_memory=False)


features = ['category_id', 'views', 'likes', 'dislikes','comment_count']

# separating out dimensions
x = df.loc[:, features].values

#y= df.loc[:,['title']].values

x = StandardScaler().fit_transform(x)

pca= PCA(n_components=2)

principalComponents = pca.fit_transform(x)

principalDf= pd.DataFrame(data = principalComponents, columns = ['Principal Component 1', 'Principal Component 2'])

finalDf = pd.concat([principalDf, df[['channel_title']]], axis = 1)



y=finalDf['Principal Component 1']
plot = plt.scatter(principalComponents[:,0], principalComponents[:,1], c=y)
plt.legend(handles=plot.legend_elements()[0], labels=list(finalDf['Principal Component 2']))

principalDf[['Principal Component 1', 'Principal Component 2']].plot()


plt.show()


print('Explained variance ratio: ', pca.explained_variance_ratio_)
print('Explained variance: ', pca.explained_variance_)
print('PCA Components: ', pca.components_)



# Task 5 --- Numeric data 
#readig the csv file, change your path if it does not work
df= pd.read_csv('CAvideos.csv', 
low_memory=False)

#dropping all the non-numeric fields for PCA 

df.drop('title', axis=1, inplace=True)
df.drop('channel_title', axis=1, inplace=True)
df.drop('video_id', axis=1, inplace=True)
df.drop('publish_time', axis=1, inplace=True)
df.drop('tags', axis=1, inplace=True)
df.drop('thumbnail_link', axis=1, inplace=True)
df.drop('comments_disabled', axis=1, inplace=True)
df.drop('ratings_disabled', axis=1, inplace=True)
df.drop('video_error_or_removed', axis=1, inplace=True)
df.drop('description', axis=1, inplace=True)
df.drop('trending_date', axis=1, inplace=True)
#exporting only numeric fields to csv
df.to_csv('217395609-215222938-215911555—T5Data.csv')



#Cosine distance

cosDist= cosine_similarity(df)
dfCos= pd.DataFrame(cosDist)
dfCos= dfCos.iloc[:, [0,5]]
print('COSINE DIST___------>>>',dfCos)
dfCos.to_csv('217395609-215222938-215911555—T5CO.csv')
plt.plot(dfCos)
plt.ylabel('Cosine Distance')
plt.xlabel('Object Index')
plt.show()


#Euclidian distance
df['Euclidian Distance'] = np.linalg.norm(df.iloc[:, [2]].values - df.iloc[:, [3]], axis=1)
topTen= df.nlargest(100, 'Euclidian Distance')
print(topTen)
df['Euclidian Distance'].to_csv('217395609-215222938-215911555—T5EU.csv')
df[['views','Euclidian Distance']].plot()
df[['Euclidian Distance']].plot()
plt.show()

    



#Mahalonobis distance
df.drop('Euclidian Distance', axis=1, inplace=True)
numArr= df[['category_id', 'views', 'likes', 'dislikes','comment_count']].to_numpy()

def calculateMahalanobis(y=None, data=None, cov=None):
  
    y_mu = y - np.mean(data)
    if not cov:
        cov = np.cov(data.values.T)
    inv_covmat = np.linalg.inv(cov)
    left = np.dot( y_mu.T, inv_covmat)
    mahal = np.dot(left, y_mu.T)
    return mahal.diagonal()

#df['Mahalanobis'] = calculateMahalanobis(y=df, data=df[['category_id', 'views', 'likes', 'dislikes','comment_count']])
#print(df.cov())